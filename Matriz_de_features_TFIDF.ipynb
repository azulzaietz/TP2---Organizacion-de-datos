{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Matriz de features - TFIDF.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyEQS4PWtsMA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "import re\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.feature_extraction.text import TfidfTransformer"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5t74cYiy8RO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "outputId": "3d15db78-1cfa-4b88-e020-8ddeaaef5152"
      },
      "source": [
        "!pip install -U textblob\n",
        "!pip install nltk \n",
        "!pip install catboost\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: textblob in /usr/local/lib/python3.6/dist-packages (0.15.3)\n",
            "Requirement already satisfied, skipping upgrade: nltk>=3.1 in /usr/local/lib/python3.6/dist-packages (from textblob) (3.2.5)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from nltk>=3.1->textblob) (1.15.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n",
            "Requirement already satisfied: catboost in /usr/local/lib/python3.6/dist-packages (0.23.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (1.2.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (1.3.3)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eeIvuBAuCnI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv('train_features.csv')\n",
        "test = pd.read_csv('test_features.csv')\n",
        "\n",
        "text_train = pd.read_csv('train_text_limpio.csv')\n",
        "text_test = pd.read_csv('test_text_limpio.csv')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HD2G1QyAuOs2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['text'] = text_train['text']\n",
        "test['text'] = text_test['text']"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poy-ToRTygBy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Pasos NLP:\n",
        "#1: FILTRADO DE DATOS - parte en Limpieza de datos\n",
        "#2: TOKENIZACION\n",
        "#3: LEMATIZACION\n",
        "\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "ps = nltk.PorterStemmer() \n",
        "\n",
        "def nlp_text(text):\n",
        "    #filtrado de signos de puntuacion\n",
        "    text = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
        "    #tokenizacion\n",
        "    tokens = re.split('\\W+', text)\n",
        "    #lematizacion\n",
        "    text = [ps.stem(word) for word in tokens]\n",
        "    return text"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oBeuzud7eZg",
        "colab_type": "text"
      },
      "source": [
        "PARA TRAIN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDUi7U381PJx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.text.fillna(' ', inplace=True)\n",
        "test.text.fillna(' ', inplace=True)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XshDL9Ay2eaH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "990f3988-a070-445c-ddb0-6af5c0ec9cdd"
      },
      "source": [
        "tf_idf = TfidfVectorizer(analyzer=nlp_text)\n",
        "tf_idf = tf_idf.fit_transform(train.text)\n",
        "matrix_tf_idf = tf_idf.todense()\n",
        "matrix_tf_idf "
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0.       , 0.       , 0.       , ..., 0.       , 0.       ,\n",
              "         0.       ],\n",
              "        [0.       , 0.       , 0.       , ..., 0.       , 0.       ,\n",
              "         0.       ],\n",
              "        [0.       , 0.       , 0.       , ..., 0.       , 0.       ,\n",
              "         0.       ],\n",
              "        ...,\n",
              "        [0.       , 0.       , 0.       , ..., 0.       , 0.       ,\n",
              "         0.       ],\n",
              "        [0.0584109, 0.       , 0.       , ..., 0.       , 0.       ,\n",
              "         0.       ],\n",
              "        [0.       , 0.       , 0.       , ..., 0.       , 0.       ,\n",
              "         0.       ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SstszisR2sXL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b64aa530-54c5-4b6f-9b3e-e32aaf1c0599"
      },
      "source": [
        "matrix_tf_idf.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7613, 18564)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuWiAJhM20eJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "outputId": "c9ae9d21-f1df-46f4-d4f3-ece6029847d2"
      },
      "source": [
        "numeric_features = train[['cant_stop_words', 'prom_long_palabra', 'cant_puntuacion', 'cant_apariciones_keyword', 'cant_numeros', 'cant_mayusculas', 'cant_vocales']]\n",
        "numeric_features"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cant_stop_words</th>\n",
              "      <th>prom_long_palabra</th>\n",
              "      <th>cant_puntuacion</th>\n",
              "      <th>cant_apariciones_keyword</th>\n",
              "      <th>cant_numeros</th>\n",
              "      <th>cant_mayusculas</th>\n",
              "      <th>cant_vocales</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>4.384615</td>\n",
              "      <td>1</td>\n",
              "      <td>61</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>4.571429</td>\n",
              "      <td>1</td>\n",
              "      <td>61</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11</td>\n",
              "      <td>5.090909</td>\n",
              "      <td>3</td>\n",
              "      <td>61</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>7.125000</td>\n",
              "      <td>2</td>\n",
              "      <td>61</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>4.500000</td>\n",
              "      <td>2</td>\n",
              "      <td>61</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7608</th>\n",
              "      <td>2</td>\n",
              "      <td>6.636364</td>\n",
              "      <td>5</td>\n",
              "      <td>61</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7609</th>\n",
              "      <td>9</td>\n",
              "      <td>5.300000</td>\n",
              "      <td>5</td>\n",
              "      <td>61</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7610</th>\n",
              "      <td>2</td>\n",
              "      <td>7.250000</td>\n",
              "      <td>11</td>\n",
              "      <td>61</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7611</th>\n",
              "      <td>5</td>\n",
              "      <td>6.263158</td>\n",
              "      <td>5</td>\n",
              "      <td>61</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7612</th>\n",
              "      <td>3</td>\n",
              "      <td>6.307692</td>\n",
              "      <td>7</td>\n",
              "      <td>61</td>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7613 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      cant_stop_words  prom_long_palabra  ...  cant_mayusculas  cant_vocales\n",
              "0                   6           4.384615  ...               10            25\n",
              "1                   0           4.571429  ...                5            13\n",
              "2                  11           5.090909  ...                2            45\n",
              "3                   1           7.125000  ...                1            24\n",
              "4                   7           4.500000  ...                3            25\n",
              "...               ...                ...  ...              ...           ...\n",
              "7608                2           6.636364  ...                7            20\n",
              "7609                9           5.300000  ...                6            39\n",
              "7610                2           7.250000  ...               10            12\n",
              "7611                5           6.263158  ...                4            49\n",
              "7612                3           6.307692  ...               16            22\n",
              "\n",
              "[7613 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfviVDuB1gV2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "matrix_features = np.hstack((matrix_tf_idf, numeric_features))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGrbTIjt5D4x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "matriz_tfidf_train = pd.DataFrame(matrix_features)\n",
        "matriz_tfidf_train.to_csv('features_train_tf_idf.csv', index=False)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77ZDFNCJ7gb2",
        "colab_type": "text"
      },
      "source": [
        "PARA TEST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjXwB9lE7jt5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf_idf = TfidfVectorizer(analyzer=nlp_text)\n",
        "tf_idf_test = tf_idf.fit_transform(test.text)\n",
        "matrix_tf_idf_test = tf_idf_test.todense()\n",
        "\n",
        "numeric_features_test = test[['cant_stop_words', 'prom_long_palabra', 'cant_puntuacion', 'cant_apariciones_keyword', 'cant_numeros', 'cant_mayusculas', 'cant_vocales']]\n",
        "\n",
        "matrix_features_test = np.hstack((matrix_tf_idf_test, numeric_features_test))\n",
        "\n",
        "matriz_tfidf_test = pd.DataFrame(matrix_features_test)\n",
        "matriz_tfidf_test.to_csv('features_test_tf_idf.csv', index=False)"
      ],
      "execution_count": 30,
      "outputs": []
    }
  ]
}