{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Logistic Regression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUnciHKD_pIE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn import model_selection\n",
        "\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from keras.layers import  Dropout, Dense\n",
        "from keras.models import Sequential"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p05c0QNiLEUm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "e5b898e6-4514-4885-e012-d7742349e4e3"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBUcnoRi_Pn1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-Qn76p7-oyX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "id='1Pk5MK9Hs_kMUT9NotGnOKE0NPra-39YU'\n",
        "downloaded = drive.CreateFile({'id': id})\n",
        "downloaded.GetContentFile('train.csv')\n",
        "\n",
        "train = pd.read_csv('train.csv')\n",
        "\n",
        "id='1GsTM9oLtIV8-Da_fDOFWsQYMpgQ8GOYJ'\n",
        "downloaded = drive.CreateFile({'id': id})\n",
        "downloaded.GetContentFile('test.csv')\n",
        "\n",
        "test = pd.read_csv('test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXIaTFgJ_m9X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_validation, y_train, y_validation = train_test_split(train, train.target, test_size=0.3, random_state=2020)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yG9vFdhCCwg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count_vec = CountVectorizer()\n",
        "train_cv = count_vec.fit_transform(train['text'])\n",
        "test_cv = count_vec.transform(test['text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsEK6LtECpjv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_cv, x_validation_cv, y_train_cv, y_validation_cv = train_test_split(train_cv, train.target, test_size=0.3, random_state=2020)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEKkW5CoE1-r",
        "colab_type": "text"
      },
      "source": [
        "CountVector + LogisticRegression sin limpiar el Text, ya que observamos que arroja mejores resultados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdkFVOQzCFa5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf_logreg = LogisticRegression(C=1.0)\n",
        "clf_logreg.fit(x_train_cv, y_train_cv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAzxRR9yBm_c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = clf_logreg.predict(test_cv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mUZAsx3EMLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Dio 0.78\n",
        "submission_1 = pd.DataFrame({'id': test['id'], 'target':pred})\n",
        "submission_1.to_csv('submission.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}